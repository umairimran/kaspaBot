The slogan “don’t trust, verify!” is often misunderstood. Many people board airplanes without verifying the pilot or the aircraft; they eat at restaurants without knowing what is in their food; they take medications without checking the supply chain. This raises the question: why would one take extraordinary measures to protect their money while neglecting to protect their life?

This situation reminds me of Jacob, the forefather of Israel, who crossed the Jordan River back to his homeland about 3,500 years ago. According to later Talmudic Rabbis, he forgot a few small items (think of dust UTXOs) and returned to the east bank in the middle of the night to retrieve them. This was dangerous, and he encountered a mysterious figure who wrestled with him, resulting in a limp, a divine blessing, and a new name—Israel. The Talmud concludes that the possessions of the righteous are dearer to them than their bodies, and they care about their possessions because they do not partake in stolen property.

The connection between this story and SPV sync mode based on multiplicative-hash UTXO commitments is significant. Verifying the proper functioning of all external systems one relies on is infeasible and unscalable. Civilization is about scaling up function and trust, and focusing solely on money verification is peculiar and can lead to complications.

Fiat currency is problematic due to unpredictable inflation, political corruption in money printing, and regulatory attempts to control financial transfers, eliminate cash, and restrict economic freedom. Cryptocurrencies offer predictable issuance and censorship resistance. The property of “no fraudulent transaction ever occurring in this currency system” is not the primary concern for users. When joining a cryptocurrency system, checking its issuance and decentralization is far more important than verifying the historical validity of transactions.

Users should focus on the state of their node being the one most likely to prevail by economic majority, rather than its validity in an abstract sense. The primary goal of consensus systems is to facilitate agreement, not enforce consistency. If the economic majority maintains a ledger that includes an invalid transaction from history, the system can still serve its purpose. Users are protected from unsafe networks as long as they can assume efficient communication methods exist to inform them of any issues. This novel way to diffuse information is facilitated by the Internet and the broader concept of civilization.

Users, like those boarding airplanes or dining at restaurants, assume they are engaging with a functioning system and that information about past security breaches would reach them through conventional channels. These channels are typically reliable due to the involvement of highly-staked, ideological, or philanthropic whistleblowers who verify the ledger, or previous users harmed by the system’s failures, thus granting the system herd immunity. Running full nodes is crucial for the ledger’s integrity, although the marginal utility of doing so is rapidly decreasing.

In summary, if you are considering joining the IOTA network, it is advisable to research it first.

Bitcoin’s Initial Blockchain Download (IBD) is the process by which new nodes join the network. The ethos of Bitcoin core developers is “don’t trust, verify!”, leading new nodes to download and verify the entire history of the Bitcoin ledger. This design limits Bitcoin’s throughput to enable fast IBD, as processing too many transactions per second would complicate verification for users joining in the future.

In 2013, my advisor shared a paper titled “Bitcoin: A Peer-to-Peer Electronic Cash System.” The narrative has since shifted to “Bitcoin: An Electronic Store of Value,” with the notion that attempts to create a peer-to-peer electronic cash coin are scams.

Kaspa aims to revive Satoshi Nakamoto's vision. PHANTOM is a generalization of Nakamoto Consensus that supports concurrency. It adheres to the same principles as Nakamoto Consensus, and implementing PHANTOM is essential for achieving the vision of electronic cash. Kaspa utilizes Directed Acyclic Graphs (DAGs) because of our expertise in this area, and we aim to facilitate transactions in a manner akin to receiving results from a Google search or sending an email.

Additionally, Kaspa seeks to create a base layer that prioritizes the needs of crypto-informed users. This involves implementing a default node that skips historical verification, making it an optional operation reliant on fewer archival nodes maintained by certain entities. This situation mirrors Bitcoin, where most full nodes prune data necessary for syncing newcomers. However, archival nodes can still prove fraudulent transactions by providing Merkle witnesses for inclusion in the relevant blocks.

Kaspa nodes prune block data by default, and new nodes sync in SPV mode, downloading and verifying only block headers. This approach does not impose a stronger trust assumption than a history-verifying node; it simply requires different operations. The node requests the UTXO set from untrusted peers and verifies it against the UTXO commitment embedded in the latest received header. If there is a mismatch, the node bans the sending peers and requests the UTXO set from new untrusted peers. If they match, the node checks for unexpected inflation by comparing the sum of UTXOs to the specified minting schedule, which can be done with block headers.

To scale Nakamoto Consensus, I propose several suggestions:

1. **Latency Constraint on Consensus**: Transition from the longest-chain rule to PHANTOM, which is tolerant of predetermined upper bounds on latency.
2. **CPU Consumption**: Process fewer transactions per second on Layer 1 while supporting large payloads that are CPU-efficient, enabling healthy Layer 2 solutions (e.g., SN/TARK proofs for Zero-Knowledge Rollups).
3. **Bandwidth Consumption**: Design sharding of data and data availability proofs, similar to Ethereum 2.0, which is an open research question since Proof of Work lacks native identities for sharding.
4. **Memory Consumption and Disk I/O**: Implement class group-based accumulators that require no trusted setup, allowing for UTXO pruning and operation as a stateless client. Challenges include user experience in storing and updating witnesses and balancing memory savings against higher CPU consumption.
5. **Storage**: Prune block data to reduce storage requirements significantly. Consider also pruning block headers, although this raises questions about how new nodes can ensure they are syncing to the consensus state rather than a stale or malicious branch.
6. **IBD Time**: Implement a DAG-adapted version of FlyClient to reduce the cost of syncing a new node from O(num of blocks in history) to O(log(num of blocks in history)). This does not reduce storage at the syncer but allows the syncee to sync without downloading the entire history of block headers.

In conclusion, Kaspa is a Proof of Work system optimized for informed users rather than ideologues. Its throughput should be constrained by real-time performance considerations rather than the performance of downloading and verifying historical ledgers, which serve as an auxiliary trust gateway rather than the primary pillar of trust in the system.

Kaspa aims to achieve 100 blocks per second, and to facilitate this, nodes should prune data by default. New nodes should sync against the heaviest PoW DAG, which is most likely to represent the current consensus view. Node operators must connect to a sufficient number of peers to avoid being eclipsed from the network, ensuring they are informed about historical issues such as invalid blocks and finality violations, which are recorded and propagated by full nodes to keep new nodes aware of what they are syncing.